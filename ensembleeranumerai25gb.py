# -*- coding: utf-8 -*-
"""ensembleeraNUMERAI25GB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10qlKUsspVF0fUwjGYprzgmia1ju-jP23
"""

!cat /proc/cpuinfo

#have to run one by one 
import pandas as pd
import numpy as np
from google.colab import drive
from sklearn.preprocessing import LabelEncoder
drive.mount('drive')
def trpipeline(X_train,p=1):

    X_train['era']=LabelEncoder().fit_transform(X_train['era'])

    

    eraf = np.arange(p,X_train['era'].unique().max(),4)

    X_t1 = X_train[X_train['era'].isin(eraf)]
    col = X_t1.drop(['era','data_type'], axis=1).columns
    X_t1[col]=X_t1[col].astype('float32')
   # X_t1.to_csv('/content/drive/My Drive/CURRDATA/era1.csv')

   # h=pd.read_csv("/content/drive/My Drive/CURRDATA/era1.csv")
    higher= X_t1[X_t1['era'] > X_t1['era'].median()]
    higher.to_csv("/content/drive/My Drive/CURRDATA/highera.csv")

def predpipeline(X_val,file_n):
    X_val['era']=LabelEncoder().fit_transform(X_val['era'])

    col2 =X_val.drop(['era','data_type'],axis=1).columns
    X_val[col2]=X_val[col2].astype('float32')
    X_val.to_csv('/content/drive/My Drive/CURRDATA/'+file_n)
# any other feature selection will be accounted for later on 

#X_in =pd.read_parquet('/content/drive/My Drive/CURRDATA/414_v3_numerai_training_data.parquet')
X_vin = pd.read_parquet('/content/drive/My Drive/CURRDATA/414_v3_numerai_validation_data.parquet')
#X_livein = pd.read_parquet('/content/drive/My Drive/CURRDATA/415_v3_numerai_live_data.parquet')
#trpipeline(X_in)
predpipeline(X_vin,'vera1.csv')
#predpipeline(X_livein,'liveera.csv')

!pip install eli5 numerapi catboost lightgbm

import numpy as np
import pyarrow.parquet as pq
import eli5
import pandas as pd
import seaborn as sns
import scipy
import matplotlib.pyplot as plt
import time
import joblib
from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder
from sklearn.model_selection import KFold, TimeSeriesSplit, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import SelectFromModel
from eli5.sklearn import PermutationImportance
from lightgbm import LGBMRegressor as lgb,plot_importance
from catboost import CatBoostRegressor
from numerapi import NumerAPI
from google.colab import drive
from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.feature_selection import mutual_info_regression
#Init
#LabelEncoder
#OneHotAutoEncoder
#Float32 map
#_neutralize
#FeatImpSelect
#FitEnsembleGridSearchC
# a group of eras must be specified to prevent leakage accross eras
# Does not perform well just shuffle K-Fold
#class TimeSeriesSplitGroups(_BaseKFold):
#    def __init__(self,n_splits):
 #       super.__init__(n_splits,shuffle=False,random_state=None)
#   
#    def split(self,X,y=None, groups):
       
 #       X,y, groups = indexable(X,y,groups)
 #       n_samples = _num_samples(X)
 #       n_folds = n_splits+ 1
 #       group_list= np.unique(groups)
  #      n_groups=(len(group_list))
 #       if n_folds > n_groups:
 #           raise ValueError("Cannot have folds ={0} greater")
 #       indicies = np.arange(n_samples)
  #      test_size= n_groups//n_folds
 #       test_starts = range(test_size +n_groups % n_folds, n_groups,test_size)
  #      test_starts =list(test_starts )[::-1]
  #      for test in test_starts:
  #          yield(indicies[groups.isin(group_list[:test_start])],indicies[groups.isin(group_list[test_start: test_start + test_size)])


class EnsembleModel():
    def __init__(self,public_id,secret_key,test_app= True):
        drive.mount('drive')
        
     #   print(NumerAPI().get_current_round())
        
        self.napi = NumerAPI(public_id=public_id, secret_key=secret_key)

        
        #self.X_era=  pd.read_csv("/content/drive/My Drive/CURRDATA/highera.csv")
      #  targetfeat = [c for c in self.X_era.columns if c.startswith('target')] 
      #  targetfeat_era = [t for t in targetfeat if t!= 'target' ] 
       
            
          #  self.X_v = self.X_v.fillna(self.X_v.median(skipna= True))
           # self.y_v = self.y_v.fillna(self.y_v.median(skipna =True))
        

        
     #   y_train = X_train['target']


     #   self.X_t=X_train.drop(['id','data_type'],axis=1)

    #    self.X_t = self.X_t.drop(targetfeat,axis=1)

      #  self.X_t = self.X_t.fillna(self.X_t.median(skipna=True))

   #     self.y_t= y_train
     #   self.y_t = self.y_t.fillna(self.y_t.median(skipna=True ))
        
   # since live data is only one era, we need to use the median for all eras
        
            # if val_app:
        self.X_v=pd.read_csv("/content/drive/My Drive/CURRDATA/vera1.csv")
        targetfeat = [c for c in self.X_v.columns if c.startswith('target')] 
        
        self.y_v=self.X_v['target']
        self.v_id = self.X_v.reset_index()['id']
        self.X_v=self.X_v.drop(['id','data_type'],axis=1)
        self.X_v= self.X_v.drop(targetfeat,axis=1)


        
        #self.X_live=[]
       # print('error')
        if test_app:
            self.X_live= pd.read_csv("/content/drive/My Drive/CURRDATA/liveera.csv")
            targetfeat = [c for c in self.X_live.columns if c.startswith('target')] 
           # targetfeat_era = [t for t in targetfeat if t!= 'target' ] 
        #self.X_v= pd.concat([self.X_val,self.X_live[self.X_live['data_type']=='validation']])
          #  self.X_live = self.X_live [ self.X_live['data_type']=='live']
            self.t_id = self.X_live.reset_index()['id']
            self.X_live=self.X_live.drop('data_type',axis=1)
            self.X_live= self.X_live.drop(targetfeat,axis=1)
            self.cols = self.X_live.columns
            
        
          
            #self.X_live = self.X_live.fillna(self.X_t.median(skipna=True))
          

        # neglect other targets
      #  X_era= self.X_era
           #     X_era = self.X_era[self.X_era[self.cat_col].isin(era_filters[m])]
           
        
    #    self.X_era = self.X_era.drop(['id','data_type'],axis=1)
     #   self.y_t = self.X_era['target']
     #   self.X_era =self.X_era.drop(targetfeat,axis=1)
    #    self.era_cols = self.X_era.columns
     #   self.cat_col='era'
    #    self.num_col=self.X_era.drop(self.cat_col,axis =1).columns
        #self.cols = self.X_era.drop('target',axis=1).columns
        self.drop_feat_imp1= None
        self.drop_feat_imp2 =None
        self.riskyF=None
        self.prop_l= None
        self.prop_c= None
        self.prop_ce=None
        self.prope_le=None
        self.era_overlap=4
     #   self.X_era.head()
        # double check 
    #    print('second error')
     #   if self.X_t.isnull().sum() != 0:
      #      raise ValueError("Missing Values X_t")
    #    print('third error')   
        #elif self.y_t.isnull().sum()!=0:
     #       raise ValueError("Missing values y_t")
            
      #  elif self.X_v.isnull().sum() !=0:
      #      raise ValueError("Missing Values X_v")
            
     #   elif self.y_v.isnull().sum() !=0:
     #       raise ValueError("Missing values y_v")
            
     #   elif self.X_live.isnull().sum() !=0:
     #       raise ValueError("Missing Values X_live")
          
     #   elif self.X_era.isnull().sum() !=j0:
     #       raise ValueError("Missing values X_era")
            
        # activate NumerAI profile connection instance

        
# interesting 
    def VIF(self,c='red'):
        vif=pd.DataFrame()

        vif["Factor"] =[variance_inflation_factor(self.X_t.drop(self.cat_col,axis=1).values, i) for i in range(self.X_t.drop(self.cat_col,axis= 1).shape[1])]
        vif["Features"] = self.X_t.columns
        vif.plot(kind='barh',xlabel='Factor',ylabel ='Features',title='VIF Multicolinearity')
        plt.show()
        pass

    def LabelEncode(self):
        
        self.X_t[self.cat_col]= LabelEncoder().fit_transform(self.X_t[self.cat_col])
        self.X_era[self.cat_col]= LabelEncoder().fit_transform(self.X_era[self.cat_col]) 
        #init with empty array I trainval first save those models and reboot COLAB 
        #THIS IS THE ONLY WAY TO DO WITHOUT COLAN PREMIUM 
        # not enough RAM to load both at the same time 
     #   if not self.X_v.empty:
    #    self.X_v[self.cat_col]= LabelEncoder().fit_transform(self.X_v[self.cat_col]) 
        
        self.X_t= pd.DataFrame(self.X_t)
        self.X_t.columns = self.cols

        self.X_era= pd.DataFrame(self.X_era)
        self.X_era.columns = self.era_cols

  #      self.X_v= pd.DataFrame(self.X_v)
   #     self.X_v.columns = self.cols


   #     print('neut group test {}'.format(self.NormNeutralizedPredGroup(self.X_v,self.num_col,self.y_v,0.1)))
    #    print('neut test {}'.format(self.NormNeutralizedPred(self.X_v,self.num_col,self.y_v.values.reshape(-1,1),0.1)))
    #        pass
      #  
       # self.X_live[self.cat_col]= LabelEncoder().fit_transform(self.X_live[self.cat_col])
        #self.X_live.columns = self.cols
       #     pass 
        return self
   # reduce memory RAM
   #quantization removes too much info
    def FloatEncode(self,d_type='float32'):
       
   #     self.X_t[self.num_col]=self.X_t[self.num_col].astype(d_type)
    #    self.y_t = self.y_t.astype(d_type)



        self.X_era[self.num_col] = self.X_era[self.num_col].astype(d_type)
        #if not self.X_v.empty():
     #   self.X_v[self.num_col]= self.X_v[self.num_col].astype(d_type)
      #  self.y_v=self.y_v.astype(d_type)
     #       
        #if not self.X_live.empty():
   #     self.X_live[self.num_col] = self.X_live[self.num_col].astype(d_type)
         #    pass
        
        return self
   # trees split on accross binary era dimensions
    def OneHotEncode(self):
   #     self.X_t=OneHotEncoder().fit_transform(self.X_t)
  #      self.X_t= pd.DataFrame(self.X_t)
  #      self.X_t.columns = self.cols
        
  #      self.X_era = OneHotEncoder().fit_transform(self.X_era) 
  #      self.X_era= pd.DataFrame(self.X_era)
  #      self.X_era.columns = self.era_cols
        
   #     self.X_v=OneHotEncoder().fit_transform(self.X_v)
    #    self.X_v= pd.DataFrame(self.X_v)
    #    self.X_v.columns = self.cols
        
        self.X_live= OneHotEncoder().fit_transform(self.X_live)
        self.X_v= pd.DataFrame(self.X_v)
        self.X_v.columns = self.cols
        #pass 
        return self

  # feature discrimination based on feat_imp 
    def FeatImpSelection(self,init_paramsl,gridft,n_splits=3,perc=0.90,perc_2 = 0.80,feat_color='skyblue'):
        
        st_time=time.time()
      #  ftss=KFold(n_splits=n_splits,shuffle=True,random_state=None)
        # grid search takes up far too much time on v4 but not v3
        lg_fu= lgb(**init_paramsl)
      #  print(len(self.X_t.columns))
        
        
       # gft= GridSearchCV(lg_fu,gridft)
       # gft.fit(self.X_era,self.y_t)

        

    #    lg_fu.set_params(**gft.best_params_)
        lg_fu.fit(self.X_era,self.y_t,feature_name='auto')
      #  boost = lg_fu.booster_
    
      #  ft_name1=boost.feature_name()
        ft_name=self.X_era.columns
    
       # if (ft_name1==ft_name2).all():
      #      ft_name=ft_name2
    #print(ft_name)
        ft_imp=lg_fu.feature_importances_
   # print(ft_imp)
    # select the top 80 percent feature importance
      
    
    #plt.bar(ft_name,ft_imp,color='skyblue',)
        plot_importance(lg_fu,figsize=(100,160),color=feat_color)
        
        plt.xlabel('Features')
        plt.ylabel('Gini Split based Feature Importance')
        plt.show()
    
        sort_imp_ind= np.argsort(-ft_imp)
    #print(sort_imp_ind)
        sorted_ft_name= self.X_era.columns[sort_imp_ind]
        ft_name_selected= sorted_ft_name[0:int(perc * len(sorted_ft_name))]
    #print(ft_name_selected)

        self.drop_feat_imp1=self.X_era.drop(ft_name_selected,axis=1).columns
        
      #  
      #  self.X_t = self.X_t.drop(self.drop_feat_imp1,axis=1)
     #   self.X_v = self.X_v.drop(self.drop_feat_imp1,axis=1)
        #self.X_era = self.X_era.drop(self.drop_feat_imp1,axis=1 )# declear below 
     #   curr_cols = self.X_era.drop(self.drop_feat_imp1,axis=1 ).columns 
        #rf = RandomForestRegressor().fit(self.X_t,self.y_t)
        #print('Now starting PI')
     #   perminst = PermutationImportance(lg_fu)#cv 
      #  perminst.fit(self.X_era,self.y_t)
        
# perm.feature_importances_ attribute is now available, it can be used
# for feature selection - let's e.g. select features which increase
# accuracy by at least 0.05:
        # MSE should be auto implemented
    #    PIFilter = SelectFromModel(perminst, threshold=0.05, prefit=True)

        
       # self.X_t = PIFilter.transform(self.X_t)
        #self.X_v= PIFilter.transform(self.X_v)
       # self.X_era= PIFilter.transform(self.X_era)
      #  ft_imp_2 = perminst.feature_importances_
       # plot_importance(perminst,figsize=(50,30),color=feat_color)
#        ft_imp_2 = mutual_info_regression(self.X_era, self.y_t)

    #plt.bar(ft_name,ft_imp,color='skyblue',)
      #  plot_importance(lg_fu,figsize=(50,30),color=feat_color)
      #  plt.show()
    #plt.xlabel('Features')
    #plt.ylabel('Gini Split based Feature Importance')

    
    
  #      sort_imp_ind_2= np.argsort(-ft_imp_2)
    #print(sort_imp_ind)
  #      sorted_ft_name_2= self.X_era.columns[sort_imp_ind_2]
  #      ft_name_selected_2= sorted_ft_name_2[0:int(perc_2 * len(sorted_ft_name_2))]
    #print(ft_name_selected)

  #      self.drop_feat_imp2=self.X_era.drop(ft_name_selected_2,axis=1).columns
      #   = drop_col_2
        
    #    self.X_t = self.X_t.drop(self.drop_feat_imp2,axis=1)
    #    self.X_v = self.X_v.drop(self.drop_feat_imp2,axis=1)
       # self.X_era = self.X_era.drop(self.drop_feat_imp1,axis=1 )
  #      self.X_era = self.X_era.drop(self.drop_feat_imp2,axis=1 )
    #   # print(len(self.X_t.columns))
        # how to obtain columns dropped after transform
        # use documentation for selectfrom model
       # self.drop_feat_imp2 = [curr_cols.remove(e) for e in PIFilter.get_feature_names_out()]
      #  self.X_t=pd.DataFrame(self.X_t)
   #   self.X_t.columns = PIFilter.get_feature_names_out()


    #    self.X_v=pd.DataFrame(self.X_v)
    #    self.X_v.columns = PIFilter.get_feature_names_out()

    #    self.X_era =  pd.DataFrame(self.X_era)
    #    self.X_era.columns  = ['id',PIFilter.get_features_names().flatten(),'target']
        
        
        drop_feat= pd.DataFrame()
#        drop_feat2= pd.DataFrame()
        drop_feat['drop_feat1']= self.drop_feat_imp1
 #       drop_feat2['drop_feat2']= self.drop_feat_imp2
        drop_feat.to_csv('/content/drive/My Drive/drop_feat.csv',encoding='utf-8', index=False)
  #      drop_feat2.to_csv('/content/drive/My Drive/drop_feat2.csv',encoding='utf-8', index=False)
        print('Time taken {}'.format(time.time()-st_time))
        return self
        
    #create ensemble here
# post ensemble model crap 
# neuti
# saving and loading model
# reduce feature exposure aka overfitting
    # post processing
    # this does not account over eras
    @staticmethod
    def NormNeutralizedPred(df,neut_col,y_pred,proportion) -> np.array:
        exposures = df[neut_col].values
        score=( y_pred - proportion* exposures.dot(np.linalg.pinv(exposures).dot(y_pred)))
        score = score.reshape(-1,1)/score.reshape(-1,1).std()
        score = MinMaxScaler().fit_transform(score).reshape(-1,1)
        return score
   # era based neut
    @staticmethod
    def NormNeutralizedPredGroup(df,neut_col,y_pred,proportion,cat_col='era')->np.array:
        neut_col= []
        unique_eras = df[cat_col].unique()
        computed=[]
        for u in unique_eras:
            df_era=df[df[cat_col]==u]
            scores=y_pred[df_era.index].values
            
            scores2=[]
            for x in scores.T:
                x=(scipy.stats.rankdata(x,method ='ordinal') -.5)
                x=scipy.stats.norm.ppf(x)
                scores2.append(x)
            
            scores=np.array(scores2)
            exposures = df_era[neut_col].values
        # ensure it is float32 for memeory and comp efficency 
            scores -= proportion * exposures.dot(np.linalg.pinv(exposures.astype('float32'))).dot(scores.astype('float32'))
            scores /= scores.std(ddof=0)
            computed.append(scores)
        forecast =np.concatenate(computed)
        forecast= MinMaxScaler().fit_transform(forecast)
        return forecast
   
    @staticmethod
    def RiskiestFeat(df,y_true,y_pred,top_count,cat_col='era') -> list:
        features= [c for c in df.columns if c.startswith('feature')]
        df2= df.copy()
        df2['target']=y_true
        df2['preds']=y_pred
        all_features_corrs= df2.groupby(cat_col).apply(lambda x: x[features].corrwith(x['target']))
        feature_corr_vol = all_features_corrs.std() 
        feature_exposure_list=[]
        for feature in features:
            feature_exposure_list.append(np.corrcoef(df2[feature],df2['preds'])[0,1])
        feature_exposure_list = pd.Series(feature_exposure_list,index =features)
        riskiest_features = (feature_exposure_list.abs() * feature_corr_vol).sort_values()[-int(top_count*len(feature_exposure_list)):].index.tolist()
        return riskiest_features
    #Return Pearson product-moment correlation coefficients.        
    @staticmethod
    def CorrelationScore(y_true,y_pred) -> np.float32:
        frame=pd.DataFrame()
        frame['true']=y_true
        frame['pred']=y_pred
        return np.corrcoef(frame['true'],frame['pred'])[0,1]
    
    @staticmethod
    def SaveModel(model,model_file_name,path=None):
        model.save_model(path+model_file_name)
        pass
   
    @staticmethod 
    def LoadModel(model_file_name,path=None)->object: 
        model = CatBoostRegressor().load_model(path+model_file_name)
        return model 
    
    def SavePredictions(self,y_pred,file_name,model_id,file_ex='.csv',path=None,upload= True ):
        if self.X_live.empty !=0:
            results=pd.DataFrame()
            results['id']= self.t_id
            results['prediction']=y_pred
            results.to_csv(path+file_name+file_ex,index=False)
            if upload:
                submission_id = self.napi.upload_predictions(path+file_name+file_ex, model_id=model_id)
                pass
            
 
    def FitEnsemble(self,init_paramsl,init_paramsc,gridl,gridc,
                               Npochs = 1,n_splits= 3,models_app=True,plt=False,neut=True,shuffle=True)->dict:
        st_time=time.time()
        cbr=CatBoostRegressor(**init_paramsc)
       # lg = lgb(**init_paramsl)
    
        if models_app:
            models=dict()
            pass
    
        pred_c=np.zeros(len(self.X_v[self.cat_col].values.reshape(-1,1)))
       # pred_l=np.zeros(len(self.X_v[self.cat_col].values.reshape( -1,1)))
  #  pred_lt=np.zeros( len(X_train['era'].values.reshape( -1,1)))
    
    #k = KFold(N_Fold)
    # dobule split on training 
    # 
        tss=KFold(n_splits=n_splits,shuffle =shuffle,random_state=None)

    
        for i in range(Npochs):
            
            for fold_, (splitter) in enumerate(tss.split(self.X_t,self.y_t)):
               
               # tr_idx, val_idx = splitter # for cv grid_search 
               
               # cbr.grid_search(gridc, self.X_t.iloc[tr_idx],self.y_t.iloc[tr_idx],cv=tss,plot=plt)
               
                print("for CatBoostReg @ {} Fold the Training Corr is {}".format(fold_
                             ,self.CorrelationScore(self.y_t.iloc[tr_idx],cbr.predict(self.X_t.iloc[tr_idx]))))
           #     print("for CatBoostReg @ sub {} Fold the Val Corr is {}".format(fold_
                     #        ,self.CorrelationScore(self.y_t.iloc[val_idx],cbr.predict(self.X_t.iloc[val_idx]))))

        #        glg= GridSearchCV(estimator=lg,param_grid=gridl,cv =tss)
         #       glg.fit(self.X_t.iloc[tr_idx],self.y_t.iloc[tr_idx])
                
             # grid search updates the parameters of the class instance no worries to update with pointer from dict
           # cbr.set_params
                
       #     
          #      print("for LightGBMReg @ {} Fold the Training Corr is {}".format(fold_
           #     ,self.CorrelationScore(self.y_t.iloc[tr_idx],glg.predict(self.X_t.iloc[tr_idx]))))
            #    print("for LightGBMReg @ sub {} Fold the Val Corr is {}".format(fold_
             #   ,self.CorrelationScore(self.y_t.iloc[val_idx],glg.predict(self.X_t.iloc[val_idx]))))

                
          
      #  print("for light gbm the Val Corr is {}".format(correlation_score(y_train,glg.predict(X_train))))            
              #  pred_l+= glg.predict(self.X_v)/n_splits 
             #   pred_c= cbr.predict(self.X_v)/n_splits
            #pred_l+= glg.predict(X_test)/N_Fold
            
         #   pred_lt += glg.predict(X_train)
                if models_app:
               #     cur_key1='LightGBMReg Model @ TS Fold '+str(fold_)
                #    cur_key2='CatBoostReg Model @ TS Fold ' + str(fold_)
                # append to dict for reproduction X_test is too much RAM seperate process VM
                #    models[cur_key1]=(glg)
                #    models[cur_key2]=(cbr)                  
                    self.SaveModel(cbr,'model CBR @ Fold ' +str(fold_),path='/numeraimodels')
                    pass
   # end of epoch final func protocol 

       # (df,neut_col,y_pred, prop)
       #( df, y_true,y_pred, top_countperc))
       # pred_cl=np.mean([pred_c,pred_l],axis = 0)
        # find the riskiest features to neutralize for to reduece overfitting 
        self.riskyF= self.RiskiestFeat(self.X_v, self.y_v, pred_c,0.3)
        
#   pred2t=interpscale(pred_lt,0 ,1 )
 #   print(" for light gbm the Training Corr is { }".format(correlation_score(y_train,pred2t)))
    #    print(" for LightGBMReg the Val Corr is {}".format(self.CorrelationScore(self.y_v,pred_l)))
        print(" for CatBoostReg the Val Cross is {}".format(self.CorrelationScore(self.y_v,pred_c)))
     #   print(" for bagged ensemble of LightGBMReg + CatBoostReg the Val Cross is {}".format(self.CorrelationScore(self.y_v,pred_cl)))
        

        # consider neut case   
        if neut:
            prop=np.arange(0.05,1,0.05)
            
      #      predneut_l = [self.CorrelationScore(self.y_v
       #     ,self.NormNeutralizedPredGroup(self.X_v,self.riskyF,pred_l,l)) for l in prop ]
        #    neutindex_l=np.where(predneut_l==np.max(predneut_l ))
         #   self.prop_l= prop[neutindex_l]
          #  LightGBMResNorm = self.NormNeutralizedPred(self.X_v,self.riskF,pred_l,prop[neutindex_l])
           # print(" for LightGBMReg the Neutralized Val Corr is {} and optimal with proportion {}"
            #      .format(predneut_l[neutindex_l], prop[neutindex_l]))
            

            predneut_c = [self.CorrelationScore(self.y_v
            ,self.NormNeutralizedPredGroup(self.X_v,self.riskyF,pred_c,c)) for c in prop ]
            neutindex_c=np.where(predneut_c==np.max(predneut_c ))
            self.prop_c =prop[neutindex_c]
            CatBoostResNorm = self.NormNeutralizedPredGroup(self.X_v,self.riskyF,pred_c,prop[neutindex_c])
            print(" for CatBoostReg the Neutralized Val Corr is {} and optimal with proportion {}".format(predneut_c[neutindex_c], prop[neutindex_c]))

         #   EnsembleNormRes = np.mean([LightGBMResNorm,CatBoostResNorm],axis=0)
          #  predneut_cl = self.CorrelationScore(self.y_v, EnsembleNormRes )
          #  print(" for CatBoostReg the Neutralized Val Corr is {} and optimal with proportions in LGBM {} and CBR {}".format(
           #         predneut_cl,prop[neutindex_l],prop[neutindex_c])
           # pass
    # decide which model to save afterwards
        if models_app:
            print("Total time for ensemble train_val is {}".format((time.time()-st_time)))
            return models

    def PredictSubmitEnsemble(self,models,file_name,model_id,n_splits=3,proportion=0.1,save_m=True,up=False ):
        
        while True: 
            
            pred_c=np.zeros(len(self.X_live[self.cat_col].values.reshape(-1,1)))
           # pred_l= np.zeros(len(self.X_live[self.cat_col].values.reshape(-1,1)))
            
            for fold_ in range(n_splits):
               # cur_key1='LightGBMReg Model @ TS Fold '+str(_fold)
                cur_key2='CatBoostReg Model @ TS Fold ' + str(fold_)
            
               # model_l = models[cur_key1]
                model_c = models[cur_key2]
                
                    
                #    self.SaveModel(model_l,'model LGB @ Fold '+str(_fold),path='/numeraimodels')
                    
# neut riskiest feat, cosnider the vol of the corr of each feat with target                
            
               # pred_l += model_l.predict(self.X_live.drop('id',axis= 1))/n_splits
                pred_c += model_c.predict(self.X_live.drop('id',axis=1))/n_splits
            

          #  predneut_l = self.NormNeutralizedPredGroup(self.X_live.drop('id',axis=1),self.riskyF,pred_l,self.prop_l)
            predneut_c = self.NormNeutralizedPredGroup(self.X_live.drop('id',axis=1),self.riskyF,pred_c,self.prop_c)

          #  predneut_cl=np.mean( [predneut_l,predneut_c],axis=0)
            self.SavePredictions(predneut_c,file_name,model_id,path='/numeraimodels',upload=up)
        
        
    def FitEnsembleOverEra(self,init_paramsc,gridc,
    Npochs = 1,n_splits= 3,sub_n_splits=3,proportion_m=0.1,models_app=False,plt=False,neut=True,shuffle=True, override=False,diagnostics =True,ms=2)->dict:
        st_time=time.time()
        #self.X_t.head()
       # lg_s=[]
        cbr_s=[]
        X_eras=[]
        y_eras=[]
       # era_filters=[]
        pred_c=np.zeros(self.X_era.shape[0])
     #   print('static method test {}'.format(self.RiskiestFeat(self.X_v,self.y_v,np.ones(len(self.y_v.values)),0.3)))
        if override:
            self.drop_feat_imp1= pd.read_csv('/content/drive/My Drive/drop_feat.csv')['drop_feat1'].values
           # self.drop_feat_imp2= pd.read_csv('/content/drive/My Drive/drop_feat2.csv')['drop_feat2'].values
            self.X_era = self.X_era.drop(self.drop_feat_imp1,axis =1)
           # self.X_era=self.X_era.drop('Unnamed: 0',axis=1)
         #   self.X_era = self.X_era.drop(self.drop_feat_imp2,axis =1)
       # pred_l=np.zeros((len(self.X_t[self.cat_col].values),era_overlap))
       # tss =KFold(n_splits= n_splits, shuffle=shuffle, random_state= None)
        sub_tss =KFold(n_splits = sub_n_splits,shuffle=shuffle,random_state=None)
    #    for i in range(1,self.era_overlap+1):
            # shifted by 1 for era_ overlap desig
        #    lg_s.append(lgb(**init_paramsl))
        for m in range(0,2):
            cbr_s.append(CatBoostRegressor(**init_paramsc))
            #X_eras.append(self.X_era.iloc[m*self.X_era.shape[0]/2:self.X_era.shape[0]/2+ m* self.X_era.shape[0]/2,:])
           # y_eras.append(self.y_t.iloc[m*self.X_era.shape[0]/2:self.X_era.shape[0]/2+ m* self.X_era.shape[0]/2])
         #   print('error')
            #era_filters.append(np.arange(i,np.max(self.X_t[self.cat_col].values),self.era_overlap).T)
     #   era_filters= np.array(era_filters)
        #print(era_filters.shape)
        
        #era_filters=np.array(era_filters)
       # era_filters
        if models_app:
            models=dict()
        
        for n in range(Npochs):
            for m in range(0,ms):
                # filter by eras as suggested in tips and analysis
               # print('error2')
                
              #  model_c = self.LoadModel('CatBoostReg Model @ Fold '+' Model_number era: '+str(m),path='/content/drive/My Drive/numeraimodels/')

                # splitting accross k fold
              #  for fold_,(tr_idx,val_idx) in enumerate(tss.split(X_te,y_te)):
                    # sub_tss acts as a mini k-fold across kfold to obtain MSE scoring based local fold hyperparamters

                cbr_s[m].grid_search(gridc,self.X_era.iloc[int(m*self.X_era.shape[0]/2):int(self.X_era.shape[0]/2 + self.X_era.shape[0]/2*m),: ],self.y_t.iloc[int(m*self.X_era.shape[0]/2):int(self.X_era.shape[0]/2 + self.X_era.shape[0]/2*m)],cv=sub_tss)
        #            glg_e= GridSearchCV(lg_s[m],param_grid=gridl, cv=tss)
         #           glg_e.fit(gridc,X_te.iloc[tr_idx],y_te.iloc[tr_idx],cv=tss,plot=plt)
                    
                    

          #          print("for LightGBMReg @ {} Fold the Training Corr is {}".format(fold_
           #         ,self.CorrelationScore(y_te.iloc[tr_idx],glg_e.predict(X_te.iloc[tr_idx]))))
            #        print("for LightGBMReg @ sub {} Fold the Val Corr is {}".format(fold_
             #       ,self.CorrelationScore(y_te.iloc[val_idx],glg_e.predict(X_te.iloc[val_idx]))))
                    
                    
                print("for CatBoostReg @ {} Fold/Model the Training Corr is {}".format(m
                              ,self.CorrelationScore(self.y_t.iloc[int(m*self.X_era.shape[0]/2):int(self.X_era.shape[0]/2 + self.X_era.shape[0]/2*m)],cbr_s[m].predict(self.X_era.iloc[int(m*self.X_era.shape[0]/2):int(self.X_era.shape[0]/2 + self.X_era.shape[0]/2*m),: ]))))
            #    print("for CatBoostReg @ sub {} Fold the Val Corr is {}".format(m
                #              ,self.CorrelationScore(y_te,model_c.predict(X_te))))


                    
              #      pred_l[:,m]+= (glg_e.predict(self.X_v))/n_splits 
              #  pred_c += ( cbr_s[m].predict(self.X_era.iloc[int(m*self.X_era.shape[0]/2):int(self.X_era.shape[0]/2 + self.X_era.shape[0]/2*m),: ]))/2
                  #  f=self.RiskiestFeat(self.X_v, self.y_v, pred_c[:,m],0.3)
                 #   print("riskiest test {} ".format(f))
                   # print('neut test {}'.format(self.NormNeutralizedPred(self.X_v,f,pred_c[:,m],0.1)))
                   # already ran set to false
             #   if models_app:
               #         cur_key1='LightGBMReg Model @ TS Fold '+str(fold_) + 'Model number:'+int(m)
                 #   cur_key2='CatBoostReg Model @ TS Fold ' + ' Model number era: ' +str(m)
                 # append to dict for reproduction X_test is too much RAM seperate process VM
                #        models[cur_key1]=(glg_e)
                 #   models[cur_key2]=(cbr_s)
                self.SaveModel(cbr_s[m],'eraCatBoostReg Model'+' Model_number: '+str(m),path='/content/drive/My Drive/numeraimodels/')
                 #   pass
#
                   # pred_le=np.mean(pred_l,axis=0)
     #   pred_ce=pred_c.reshape(-1,1)
      #  print(pred_ce.shape)
    #                # mean over eras of models
                    # now over models
                  #  pred_cle = np.mean([pred_ce,pred,le],axis=0)
         # find the riskiest features to neutralize for to reduece overfitting 
       # self.riskyF= self.RiskiestFeat(self.X_v, self.y_v, pred_ce,0.3)
      #          # google drive is mounted
      #  riskFrame = pd.DataFrame()
      #  riskFrame['risk']=self.riskyF
      #  riskFrame.to_csv('/content/drive/My Drive/riskf.csv',encoding='utf-8', index=False)
 #   pred2t=interpscale(pred_lt,0 ,1 )
    #   print(" for light gbm the Training Corr is { }".format(correlation_score(y_train,pred2t)))
                 #    print(" for LightGBMReg the Val Corr is {}".format(self.CorrelationScore(self.y_v,pred_le)))
      #  print(" for CatBoostReg the Val Cross is {}".format(self.CorrelationScore(self.y_v,pred_ce)))
                  #   print(" for bagged ensemble of LightGBMReg + CatBoostReg the Val Cross is {}".format(self.CorrelationScore(self.y_v,pred_cle)))
                    

      #  if neut:
           # prop=np.arange(0.05,1,0.05)

                   # predneut_l = [self.CorrelationScore(self.y_v
              #  ,self.NormNeutralizedPredGroup(self.X_v,self.riskyF,pred_le,l)) for l in prop ]
              #      neutindex_l=np.where(predneut_l==np.max(predneut_l ))
              #      self.prop_le= prop[neutindex_l]
              #      LightGBMResNorm = self.NormNeutralizedPred(self.X_v,pred_le,prop[neutindex_l])
              #      print(" for LightGBMReg the Neutralized Val Corr is {} and optimal with proportion {}"
              #     .format(predneut_l[neutindex_l], prop[neutindex_l]))

           # predneut_c = [self.CorrelationScore(self.y_v,self.NormNeutralizedPred(self.X_v,self.riskyF,pred_ce,c)) for c in prop ]
         #   neutindex_c=np.where(predneut_c==np.max(predneut_c ))
         #   self.prop_ce =prop[neutindex_c]
      #      CatBoostResNorm = self.NormNeutralizedPred(self.X_v,self.riskyF,pred_ce,proportion=proportion_m)
       #     print(" for CatBoostReg the Neutralized Val Corr is {}".format(self.CorrelationScore(self.y_v,CatBoostResNorm )))
       #     diagf = pd.DataFrame()
       #     diagf['id']=self.v_id
       #     diagf['prediction']=CatBoostResNorm
       #     diagf.to_csv('/content/drive/My Drive/diagf.csv',encoding ='utf-8',index=False)

               #     EnsembleNormRes = np.mean([LightGBMResNorm,CatBoostResNorm],axis=0)
                #    predneut_cl = self.CorrelationScore(self.y_v, EnsembleNormRes )
                 #   print(" for CatBoostReg the Neutralized Val Corr is {} and optimal with proportions in LGBM {} and CBR {}".format(
                  #       predneut_cl,prop[neutindex_l],prop[neutindex_c])
           # pass
     # manipulate  model to  afterwards
       # if models_app:
       #     print("Total time for ensemble train_val is {}".format((time.time()-st_time)))
       #     return models
        
        
        
        
        print("Total time for ensemble train_val is {}".format((time.time()-st_time)))
 
    def PredictSubmitEnsembleOverEra(self,model_id,n_splits=3,proportion_m = 0.25,FeatImpSelection=True,up=False,ms=2):
      
        if __name__=='__main__':
            pred_ct=np.zeros((self.X_live.shape[0]))
            pred_cv=np.zeros((self.X_v.shape[0]))
            # NEW SESSION STARTED after training
            
            #self.riskyF = pd.read_csv('/content/drive/My Drive/riskf.csv')['risk'].values
          #  pred_l= np.zeros(len(self.X_live[self.cat_col].values.reshape(-1,1),era_overlap)) 
            for m in range(0,ms):

                
             #       cur_key1='LightGBMReg Model @ TS Fold '+str(fold_) +  'Model number:'+int(m)
              #      cur_key2='CatBoostReg Model @ TS Fold ' + str(fold_) +  'Model number:'+int(m)
     
               #     model_l = models[cur_key1]
                model_c = self.LoadModel('eraCatBoostReg Model'+' Model_number: '+str(m),path='/content/drive/My Drive/numeraimodels/')
                    
                #        self.SaveModel(model_l,'model LGB @ Fold '+str(fold_)+'Model_number:'+int(m),path='/numeraimodels')
                 #       self.SaveModel(model_c,'model CBR @ Fold ' +str(fold_)+'Model_number:'+int(m),path='/numeraimodels')
     # neut riskiest feat, cosnider the vol of the corr of each feat with target                
        
                   # pred_l[:,m] += model_l.predict(self.X_live.drop('id',axis= 1))/n_splits
                if FeatImpSelection:
                    self.drop_feat_imp1= pd.read_csv('/content/drive/My Drive/drop_feat.csv')['drop_feat1'].values
                 #   self.drop_feat_imp2= pd.read_csv('/content/drive/My Drive/drop_feat2.csv')['drop_feat2'].values
                 #   drop_col1 = np.intersect1d(self.drop_feat_imp1,self.cols)
                  #  drop_col2 = np.intersect1d(self.drop_feat_imp2,self.cols)
                    self.X_live.drop(self.drop_feat_imp1,axis= 1)
                  #  self.X_live.drop(self.drop_feat_imp2,axis= 1)
                    self.X_v.drop(self.drop_feat_imp1,axis=1)
                 #   self.X_v.drop(self.drop_feat_imp2,axis=1)            


                    
                      

                pred_ct+= model_c.predict(self.X_live.drop('id',axis =1 ))/ms 
                pred_cv+= model_c.predict(self.X_v) /ms
    
           # pred_le = np.mean(pred_l,axis=0)
            #pred_ce = np.mean(pred_c,axis=1).reshape(-1,1)
           # self.riskyF= self.RiskiestFeat(self.X_v, self.y_v, pred_cv,0.3)
           # predneut_l = self.NormNeutralizedPredGroup(self.X_live.drop('id',axis=1),self.riskyF,pred_le,self.prop_le)
            predneut_ct = self.NormNeutralizedPred(self.X_live.drop('id',axis =1 ),self.X_live.drop('id',axis =1 ).columns,pred_ct,proportion_m)
           # predneut_cv = self.NormNeutralizedPred(self.X_v,self.X_v.columns,pred_cv,proportion_m)
          #  print(" for ensemble CatBoostReg the Neutralized Val Corr is {}".format(self.CorrelationScore(self.y_v,predneut_cv )))
           # predneut_cl=np.mean( [predneut_l,predneut_c],axis=0)
            #self.SavePredictions(predneut_c,file_name,model_id,path='/content/drive/My Drive/numeraimodels',upload=up) 
            resultsv=pd.DataFrame()
            resultsv['id']= self.v_id
            resultsv['prediction']=pred_cv
            resultsv.to_csv('/content/drive/My Drive/valch.csv',index=False)
            
            
            results=pd.DataFrame()
            results['id']= self.t_id
            results['prediction']=predneut_ct
            results.to_csv('/content/drive/My Drive/firstsub.csv',index=False)

public_id = 'pi'
secret_key = 'sk'
e=EnsembleModel(public_id, secret_key, test_app =True)

e.FloatEncode()

e.LabelEncode()

init_paramsl = {
    'metric':'mse',
    'importance_type':'split'
}
gridft  ={'reg_alpha': [0.1, 0.5],
    'lambda_l1': [0, 1, 1.5],
    'lambda_l2': [0, 1],
   # 'max_depth': np.arange(5,20,5),
   # 'n_estimators':np.arange(100,250,50),
    'learning_rate': [0.03, 0.01, 0.03, 0.009],
   # 'num_leaves':np.arange(25,40,5)
    }

e.FeatImpSelection(init_paramsl,gridft)

init_paramsc={ 'loss_function':'RMSE'}

gridc = {
    'learning_rate': [0.03, 0.01, 0.03, 0.009],
  #  'bagging_temperature': [0, 1,5,10],
     'max_depth': np.arange(5,20,5),
     'n_estimators':np.arange(100,250,50)
  #   'num_leaves':np.arange(25,40,5)
     }



e.FitEnsembleOverEra(init_paramsc,gridc,override = True)

e.PredictSubmitEnsembleOverEra(111)

